# ğŸ“ Lecture: Local Search, Iterative Improvement, and Hill Climbing  
**Course**: CS3151 â€“ Artificial Intelligence  
**Topic**: Local Search Strategies  
**CLO2**: Implement classical AI techniques  
**ğŸ“˜ Based on**: *Artificial Intelligence: A Modern Approach* (Russell & Norvig)

---

## ğŸ¯ Learning Objectives

By the end of this lecture, students will be able to:

- Understand the concept of **local search** and its difference from **pathfinding search**
- Implement **hill climbing** and **iterative improvement** algorithms
- Identify limitations like **local maxima**, **plateaus**, and **ridges**
- Use variants like **stochastic hill climbing** and **first-choice hill climbing**
- Apply local search to problems like **N-Queens**, **scheduling**, and **optimization**

---

## ğŸ§  Part 1: What is Local Search?

### ğŸ“˜ Definition:
**Local search algorithms** operate using a single current state and move only to neighboring states. They are typically used when the path is irrelevant, and only the solution state matters.

---

### âœ… Key Characteristics

| Feature         | Description                                          |
|-----------------|------------------------------------------------------|
| **State space** | No tree, just a graph of states                      |
| **Memory**      | Very low â€“ only current state stored                 |
| **Goal**        | Optimization (max or min value)                      |
| **Examples**    | N-Queens, Scheduling, Traveling Salesman             |

---

## ğŸ” Part 2: Iterative Improvement Algorithms

### ğŸ“˜ Definition:
**Iterative improvement** starts with an initial solution and improves it by exploring its neighbors, repeating until a stopping condition is met.

- These do not maintain a search tree or path.

---

## ğŸŒ„ Part 3: Hill Climbing Algorithm

### ğŸ“˜ Definition:
**Hill Climbing** is a local search algorithm that continuously moves to the neighboring state with the highest value.

---

### ğŸ§® Evaluation Function:
Often uses an **objective function** or **fitness score**.

- **Goal**: Maximize `f(n)` (or minimize `cost(n)`)

### âœ… Types of Hill Climbing:

| Type           | Description                                        |
|----------------|----------------------------------------------------|
| **Simple**     | Chooses best neighbor                              |
| **Stochastic** | Chooses randomly among improving neighbors         |
| **First-Choice**| Examines random neighbors until an improvement     |
| **Random Restart**| Repeats HC from multiple initial states          |

---

### ğŸ—ºï¸ Hill Climbing Landscape

- **Local maximum**: Better than neighbors but not global best.
- **Ridge**: Area with steep slope in one direction.
- **Plateau**: Flat area with no uphill path.

---

## ğŸ“ˆ Part 4: Visualization

**1D State Space Example**  
- This example shows how Hill Climbing algorithm moves through different states, trying to reach the highest point.

```markdown
         *
        * *
       *   *        â† Global maximum
      *     *
  * *         * *
 *               * â† Local maximum
```
* Hill climbing may get stuck in local maxima.

---

## ğŸ’¡ Mini Quiz #1:
**Q:** What strategy helps overcome local maxima and plateaus in hill climbing?  
**A:** **Random Restart** or **Stochastic Hill Climbing** can help overcome local maxima and plateaus by exploring different starting points or choosing random neighbors to avoid getting stuck.

---

## ğŸ’» Part 5: Python Example â€“ Hill Climbing for Max f(x)

**Problem**: Maximize `f(x) = -xÂ² + 10` in range [-10, 10]

```python
import random

def fitness(x):
    return -x**2 + 10

def hill_climb(start, step_size=1, max_iter=100):
    current = start
    for _ in range(max_iter):
        neighbors = [current + step_size, current - step_size]
        neighbor = max(neighbors, key=fitness)

        if fitness(neighbor) > fitness(current):
            current = neighbor
        else:
            break
    return current, fitness(current)

# Run
start = random.randint(-10, 10)
solution, value = hill_climb(start)
print(f"Start: {start}, Solution: {solution}, Fitness: {value}")
```
## ğŸ–¥ï¸ Sample Output

```yaml
Start: 7, Solution: 0, Fitness: 10
```
## âœï¸ Classwork

### âœ… Task 1:
**Visualize** the function `f(x) = -xÂ² + 10` and simulate **hill climbing** from **3 random starts**.

### âœ… Task 2:
**Implement first-choice hill climbing**:
- Randomly pick one neighbor.
- Move if it improves fitness.

---

## ğŸ“ Homework Assignment

- Implement **stochastic hill climbing** using Python.
- Modify **hill climbing** for the **8-Queens problem**.
- Describe **three weaknesses of hill climbing** and how **random restarts** solve them.

---

## ğŸ“Š Part 6: Comparison of Local Search Algorithms

| Algorithm               | Complete | Optimal | Space | Works For               |
|-------------------------|----------|---------|-------|-------------------------|
| **Hill Climbing**        | âŒ       | âŒ      | O(1)  | Local optima            |
| **Random Restart HC**    | âœ…       | âŒ      | O(1)  | Gets out of local maxima |
| **Simulated Annealing**  | âœ…       | âœ…*     | O(1)  | Escaping local optima   |
| **With correct cooling schedule** |          |         |       |                         |

---

## ğŸ§  Summary

- **Local search** is **memory-light**, but not guaranteed to find **global optima**.
- **Hill climbing** is a **greedy** approach that gets stuck in **local maxima**.
- Variants like **stochastic**, **first-choice**, and **random-restart** help overcome limitations.
- **Local search** is ideal for **large state spaces** where **path** is irrelevant.
